# ГЛОБАЛЬНОЕ ПРАВИЛО ЭТОГО ДОКУМЕНТА:
- БЕЗ КОНКРЕТНОГО УКАЗАНИЯ НА FEATURE К РАЗРАБОТКЕ - НИЧЕГО ДЕЛАТЬ НЕ НАДО!!!
- Если тебе ссылаются на этот файл в качестве ТЗ и не указывают конкретную feature к разработке - то без конкретного указания на конкретный раздел с именем Feature ничего разрабатывать НЕ НУЖНО! Запроси конкретные указания на имя Feature которую необходимо сейчас разработать.
- Если задание подразумевает только исследование, анализ или ПЛАНИРОВАНИЕ, то НЕ НУЖНО ничего разрабатывать! Необходимо провести только исследование, анализ или планирование.
- Текст этого файла возьми как основу и документацию для понимания бизнес сути проекта.
- Документ дополняется накопительным итогом - вверху самые старые разделы, внизу самые новые спецификации. Если какая-то спецификация ранних этапов входит в противоречение с реализованной спецификацией на более поздних этапах, то актуальной истиной является самая поздняя реализация.
- Учти все разделы всех фич описывающие логику работы, требования, техническую реализацию, ожидаемый результат и итоги реализации. Все требования должны учитываться накопительным итогом в реализации feature даже если они не указываются в тексте описания feature в явном виде.

## КОНТЕКСТ:
- В этой папке новый MVP проект n8n. Суть проекта - сделать минимальный n8n для интеграции с платформой чат-ботов Salebot.pro, сервисами Google (Google Sheets) и другими.
- Используются ДВА инстанса n8n: облачный cloud и локальный self-hosted.
- Все Workflow должны поддерживать одинаковую работу с cloud и self-hosted.

# ТЕХНИЧЕСКИЕ ТРЕБОВАНИЯ MVP:
- Указанные версии ПО - актуальные на текущий момент (Октябрь 2025). Разрешается использовать более новые стабильные версии ПО.
- Стек и версии указаны для локальной версии инстанса n8n.

## Стек и версии (self-hosted n8n)
- **n8n**: Self-hosted установка последней версии 1.118.2.
- **Python**: 3.13.14 и новее (обязательно использование `venv`).

## Сетевые настройки (self-hosted n8n)
- **Туннель для HTTPS**: Для внешних интеграций и webhook сервис доступен через отдельную VPS n8n.autsorsim.ru.
- **Доступ извне**: PROD - свободный доступ с самого хоста, а также из локальной сети. DEV - с любого компьютера.
- **Безопасность**: Для безопасного внешнего доступа — ограничивать фаерволом системы или туннелировать через SSH. Не настраивать повышенную безопасность в Docker/Compose.
- **URL локального n8n**: Собственный сервер n8n установлен и доступен по URL: http://192.168.1.60:5678/home/workflows.

## Контейнеризация (Docker/Compose) (self-hosted n8n)
- **Базовый образ**: оригинальный официальный n8n `docker.n8n.io/n8nio/n8n`.

## База данных и хранение состояния (при необходимости) (self-hosted n8n)
- **СУБД**: PostgreSQL 16, оригинальный официальный образ.

## Ограничения MVP
- Нет мониторингов/дашбордов/метрик активности поверх логов.
- Нет сложной ротации логов (только суточные файлы + простая очистка по 14 дням).
- Минимум абстракций, максимум простоты и надёжности.

## Безопасность
- **Токен API**: Все запросы к единому endpoint для внешних запросов /router/ должны иметь токен в header для post или ?x-api-key параметр для get равным .

# CREDENTIALS
Все креды - отправлены на почту 12.11.2025 21:17 (т.к. возникают проблемы при деплое и git!)

**Workflow token**
**salebotservicekey-447914-dc4c4ff21033.json** - DISABLED by GOOGLE on 12.11.2025 (exposed!)
**OAUTH**
**N8N API KEY n8n.autsorsim.ru**




# ФИЧА: Сокращение запросов к Google Sheets с помощью кэшинования справочных данных локально.

## Бизнес потребность:
Я использую google sheet как первоисточник данных, которые меняются довольно редко. Поэтому, для того чтобы при каждом запуске workflow не обращаться к ним напрямую, я хочу сначала скачать их себе в кэш, например, в data table таблицу и в workflow использовать уже данные из data table.

## ЗАДАЧА:
- Проанализируй возможные варианты решения, предложи лучшую архитектуру.
- Это MVP проект, поэтому все должно быть максимально просто и эффективно.
- Напиши такой workflow, который будет получать через сервисную учетную запись google содержимое листа google sheet, будет сохранять его 1 к 1 в таблицу data table.
- Запуск workflow нужно делать каждые 15 минут, либо вручную, либо при запуске через webhook /router?method=cache.update.
- webhook router уже существует, он является единой точкой endpoint для всех внешних запросов. После получения запроса он переадресует этот запрос 1:1 как body запроса в другие дочерние subworkflow со своими webhook и обратно после выполнения дочерних воркфлоу, он передает получившийся ответ json обратно вызывающей стороне. Поэтому в этом workflow должен быть webhook с url вида /cache/update для метода get. Плюс в get должен также передаваться в виде параметра токен доступа как ?x-api-key=LKSJDFIUYKJ (ключ апи).

## Ожидаемый результат:
- Workflow с оптимальной архитектурой, сохраняющий данные первоисточника google sheet локально в n8n в виде кэша. Работа с данными из кэш из других workflow.

## Итог реализации:
(раздел должен заполняться уже по итогам фактической реализации - в качестве документации накопительным итогом)


